{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Covid_Diagnosis_Using_CT_Scans.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsptssR3Aonf"
      },
      "source": [
        "### **Classification of CT scan images as either having Covid-19 or healthy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L1yjaqQPlrF"
      },
      "source": [
        "Installations and imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOnQom4a2v06"
      },
      "source": [
        "#installation of pillow for image resizing \n",
        "!pip install --upgrade pip\n",
        "!pip install --upgrade Pillow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJUhEOkd_L7t"
      },
      "source": [
        "##USEFUL LIBRARIES\n",
        "import numpy as np\n",
        "import scipy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "import glob\n",
        "import os\n",
        "from PIL import Image\n",
        "import zipfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K77DwhvYPrNG"
      },
      "source": [
        "Mounting of google drive to get data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJI1FhF5qydU"
      },
      "source": [
        "##MOUNTING GOOGLE DRIVE TO THIS COLAB NOTEBOOK\n",
        "from google.colab import drive\n",
        "drive._mount('/content/drive')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfArXc2MSLu0"
      },
      "source": [
        "Importing images and converting them into 1-D RGB image matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChO8STT2sTRB"
      },
      "source": [
        "##UNZIPPING THE DATA\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/HCML project/archive.zip\",'r')\n",
        "zip_ref.extractall(\"/content/dataset\")\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JSPZ28d774m"
      },
      "source": [
        "##CONVERTS A PNG INTO AN RGB MATRIX\n",
        "def image_to_matrix(image_file, grays=False):\n",
        "    img = image.imread(image_file)\n",
        "    if(len(img.shape) == 3 and img.shape[2] > 3):\n",
        "        height, width, depth = img.shape\n",
        "        new_img = np.zeros([height, width, 3])\n",
        "        for r in range(height):\n",
        "            for c in range(width):\n",
        "                new_img[r,c,:] = img[r,c,0:3]\n",
        "        img = np.copy(new_img)\n",
        "    if(grays and len(img.shape) == 3):\n",
        "        height, width = img.shape[0:2]\n",
        "        new_img = np.zeros([height, width])\n",
        "        for r in range(height):\n",
        "            for c in range(width):\n",
        "                new_img[r,c] = img[r,c,0]\n",
        "        img = new_img\n",
        "    if(len(img.shape) == 2):\n",
        "        zeros = np.where(img == 0)[0]\n",
        "        img[zeros] += 1e-7\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLvLWiVSYZKJ"
      },
      "source": [
        "def flatten(image_matrix):\n",
        "    if(len(image_matrix.shape) == 3):\n",
        "        height, width, depth = image_matrix.shape\n",
        "    else:\n",
        "        height, width = image_matrix.shape\n",
        "        depth = 1\n",
        "    flattened_values = np.zeros([height*width,depth])\n",
        "    for i, r in enumerate(image_matrix):\n",
        "        for j, c in enumerate(r):\n",
        "            flattened_values[i*width+j,:] = c\n",
        "    oneDim = []\n",
        "    for pixel in range(len(flattened_values)):\n",
        "      for RGB_value in range(3):\n",
        "        if RGB_value == 0:\n",
        "          oneDim.append(flattened_values[pixel][RGB_value])\n",
        "    return np.array(oneDim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COxpX7Ws2Vgw"
      },
      "source": [
        "#Resize image function\n",
        "def resize_image(image_file, width, height):\n",
        "  image = Image.open(image_file)\n",
        "  new_image = image.resize((width, height))\n",
        "  new_image.save(image_file)\n",
        "  return image_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW0W4AYbDga_"
      },
      "source": [
        "#reading in CT images and converting them to RGB matrices\n",
        "#########################################################\n",
        "from PIL import Image\n",
        "\n",
        "#getting patient folders (both covid and healthy)\n",
        "patient_folders = []\n",
        "target=[]\n",
        "for filepath in glob.glob(os.path.join('/content/dataset/New_Data_CoV2/Covid', '*')):\n",
        "  patient_folders.append(filepath)\n",
        "  target.append(\"Covid\")\n",
        "\n",
        "healthy_patient_folders = []\n",
        "for filepath in glob.glob(os.path.join('/content/dataset/New_Data_CoV2/Healthy', '*')):\n",
        "  patient_folders.append(filepath)\n",
        "  target.append(\"Healthy\")\n",
        "\n",
        "#convert folder lists to arrays\n",
        "patient_folders = np.array(patient_folders)\n",
        "\n",
        "#split the folders in training/testing sets\n",
        "folder_train, folder_test, y_train, y_test = train_test_split(patient_folders, target, test_size = 0.2, random_state = 0) \n",
        "\n",
        "#Convert training images to matrices and add them to a list of them\n",
        "print(\"Beginning conversion of training images to matrices\")\n",
        "train_image_matrix = []\n",
        "train_target = []\n",
        "for i in range(len(folder_train)): ##len(folder_train)\n",
        "  folder_filepath = folder_train[i]\n",
        "  category = y_train[i]\n",
        "  for png_filepath in glob.glob(os.path.join(folder_filepath, '*.png')):\n",
        "      img_filepath = resize_image(png_filepath,280,200)\n",
        "      train_image_matrix.append(flatten(image_to_matrix(img_filepath)))\n",
        "      train_target.append(category)\n",
        "  print(\"\\tAdding images folder:\", folder_filepath)\n",
        "\n",
        "#Convert testing images to matrices and add them to a list of them\n",
        "print(\"Beginning conversion of testing images to matrices\")\n",
        "test_image_matrix = []\n",
        "test_target = []\n",
        "for i in range(len(folder_test)):\n",
        "  folder_filepath = folder_test[i]\n",
        "  category = y_test[i]\n",
        "  for png_filepath in glob.glob(os.path.join(folder_filepath, '*.png')):\n",
        "      img_filepath = resize_image(png_filepath,280,200)\n",
        "      test_image_matrix.append(flatten(image_to_matrix(img_filepath)))\n",
        "      test_target.append(category)\n",
        "  print(\"\\tAdding images folder:\", folder_filepath)\n",
        "_ \n",
        "#convert image_matrix lists to arrays\n",
        "train_image_matrix = np.array(train_image_matrix)\n",
        "test_image_matrix = np.array(test_image_matrix)\n",
        "train_target = np.array(train_target)\n",
        "test_target = np.array(test_target)\n",
        "print(\"Conversion of images to matrices is complete\")\n",
        "\n",
        "#print that conversion process is complete and size of the training and testing image matrices\n",
        "print(\"Training images matrix dimensions:\", train_image_matrix.shape)\n",
        "print(\"Testing images matrix dimensions:\", test_image_matrix.shape)\n",
        "\n",
        "print(\"Training images target matrix dimensions:\", train_target.shape)\n",
        "print(\"Testing image target matrix dimensions:\", test_target.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REK4qvtvPPmj"
      },
      "source": [
        "### ***ML MODELS***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXuoRqxb7kq5"
      },
      "source": [
        "Single Decision Tree Classifer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYg7ECjA0Bb4"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apK-Mv7HSSfE"
      },
      "source": [
        "#tuning parameters of decision tree by trying different combos of max_depth and max_features\n",
        "############################################################################################\n",
        "\n",
        "depths = [3,5,7,9]\n",
        "feature_amts = [10,50,100,500,1000,2000]\n",
        "\n",
        "best_accuracy = 0\n",
        "best_depth = 0\n",
        "best_feature_amt = 0\n",
        "\n",
        "for depth in depths:\n",
        "  for feature_amt in feature_amts:\n",
        "\n",
        "    #create decision tree\n",
        "    print(\"Decision tree where max depth =\", depth, \"and max features =\", feature_amt)\n",
        "    dt = DecisionTreeClassifier(max_depth=depth, max_features=feature_amt)\n",
        "\n",
        "    #train decision tree\n",
        "    dt.fit(train_image_matrix, train_target)\n",
        "\n",
        "    #create predictions using decision tree\n",
        "    y_pred = dt.predict(test_image_matrix)\n",
        "\n",
        "    #accuracy   \n",
        "    print(\"\\tAccuracy =\", accuracy_score(test_target, y_pred)\n",
        "    if accuracy_score(test_target, y_pred) > best_accuracy:\n",
        "      best_accuracy = accuracy_score(test_target, y_pred)\n",
        "      best_depth = depth\n",
        "      best_feature_amt = feature_amt\n",
        "\n",
        "print(\"\\nBest Accuracy =\", best_accuracy)\n",
        "print(\"\\tMax Depth =\", best_depth)\n",
        "print(\"\\tMax features =\", best_feature_amt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe6iIEJ4eAhs"
      },
      "source": [
        "#create decision tree using best found configuration of parameters (aka the optimal decision tree)\n",
        "##################################################################################################\n",
        "\n",
        "#create decision tree\n",
        "dt = DecisionTreeClassifier(max_depth=5, max_features=2000)\n",
        "\n",
        "#train decision tree\n",
        "dt.fit(x_train, y_train)\n",
        "\n",
        "#create predictions using decision tree\n",
        "y_pred = dt.predict(x_test)\n",
        "\n",
        "### Performance metrics ###\n",
        "#confusion matrix\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "#accuracy\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy of optimal decision tree =\", acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPevh_wWORmP"
      },
      "source": [
        "#save optimal decision tree to a .png file\n",
        "##########################################\n",
        "\n",
        "export_graphviz(dt, out_file=\"mytree.dot\")\n",
        "with open(\"mytree.dot\") as f:\n",
        "    dot_graph = f.read()\n",
        "graphviz.Source(dot_graph)\n",
        "\n",
        "#convert .dot to .png and save it\n",
        "!dot mytree.dot -Tpng -o NewDecisionTree.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_ju9oW0EdkO"
      },
      "source": [
        "Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO6eLTBLM1Zh"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEwAz0GJEhoB"
      },
      "source": [
        "#determine what max depth for RF trees achieves best accuracy\n",
        "#############################################################\n",
        "\n",
        "best_acc = 0\n",
        "best_depth = 0\n",
        "depths = [1,2,3,4,5,6,7,8,9]\n",
        "accuracies = []\n",
        "\n",
        "for depth in depths:\n",
        "\n",
        "  #create and train RF \n",
        "  print(\"\\nTraining random forest with max depth of\",depth)\n",
        "  rf = RandomForestClassifier(max_depth=depth, random_state=0)\n",
        "\n",
        "  #train decision tree\n",
        "  scores = cross_val_score(rf, image_matrices, image_targets, cv=5)\n",
        "\n",
        "  #accuracy   \n",
        "  print(\"\\tAccuracy =\", scores.mean())\n",
        "  accuracies.append(scores.mean())\n",
        "  \n",
        "  if scores.mean() > best_acc:\n",
        "    best_acc = scores.mean()\n",
        "    best_depth = depth \n",
        "\n",
        "print(\"\\nBest accuracy achieved is\", best_acc, \"using a max depth of\", best_depth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98OPJVqrG3uJ"
      },
      "source": [
        "#plot accuracies over max depth\n",
        "###############################\n",
        "\n",
        "x_vals = range(1,10)\n",
        "plt.plot(x_vals,accuracies)\n",
        "plt.title(\"Accuracies of Random Forests with Varying Max Depths\")\n",
        "plt.xlabel(\"Max Depth\")\n",
        "plt.ylabel(\"Accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}